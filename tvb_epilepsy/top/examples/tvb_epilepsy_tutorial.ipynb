{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# TVB for Epilepsy\n"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-09-05T10:45:45.126017",
          "start_time": "2017-09-05T10:45:45.115729"
        },
        "cell_style": "center",
        "collapsed": false,
        "hide_input": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Basic configurations"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# !source activate python2.7.3\n",
        "print(1)\n",
        "%matplotlib inline\n",
        "\n",
        "import os\n",
        "import warnings\n",
        "from copy import deepcopy\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from tvb_epilepsy.base.constants.config import Config\n",
        "from tvb_epilepsy.base.utils.log_error_utils import initialize_logger\n",
        "from tvb_epilepsy.io.tvb_data_reader import TVBReader\n",
        "from tvb_epilepsy.io.h5_reader import H5Reader\n",
        "from tvb_epilepsy.io.h5_writer import H5Writer\n",
        "from tvb_epilepsy.plot.plotter import Plotter\n",
        "\n",
        "input_folder = os.path.join(os.path.expanduser(\"~\"), 'Dropbox', 'Work', 'VBtech', 'VEP', \"results\", \"CC\", \"TVB3\", \"tvb\")\n",
        "head_folder = os.path.join(os.path.expanduser(\"~\"), 'Dropbox', 'Work', 'VBtech', 'VEP', \"results\", \"CC\", \"TVB3\", \"Head\")\n",
        "output_folder = os.path.join(os.path.expanduser(\"~\"), 'Dropbox', 'Work', 'VBtech', 'VEP', \"results\", \"tests\")\n",
        "config = Config(head_folder=input_folder, output_base=output_folder, data_mode=\"tvb\") #, data_mode=\"java\"\n",
        "config.figures.MATPLOTLIB_BACKEND=\"inline\"\n",
        "config.figures.SHOW_FLAG=True\n",
        "logger = initialize_logger(__name__, config.out.FOLDER_LOGS)\n",
        "tvbreader = TVBReader()\n",
        "reader = H5Reader()\n",
        "writer = H5Writer()\n",
        "plotter = Plotter(config)\n",
        "print(1)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": true,
        "inputHidden": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!source activate python2.7.3\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "import sys \n",
        "stdout = sys.stdout\n",
        "import os\n",
        "import numpy as np\n",
        "from tvb_epilepsy.base.constants.config import Config\n",
        "from tvb_epilepsy.base.utils.log_error_utils import initialize_logger\n",
        "from tvb_epilepsy.io.h5_reader import H5Reader\n",
        "from tvb_epilepsy.io.tvb_data_reader import TVBReader\n",
        "sys.stdout = stdout\n",
        "from tvb_epilepsy.io.h5_writer import H5Writer\n",
        "from tvb_epilepsy.plot.plotter import Plotter\n",
        "\n",
        "head_folder = os.path.join(os.path.expanduser(\"~\"), 'Dropbox', 'Work', 'VBtech', 'VEP', \"results\", \"CC\", \"TVB3\", \"Head\")\n",
        "tvb_folder = os.path.join(os.path.expanduser(\"~\"), 'Dropbox', 'Work', 'VBtech', 'VEP', \"results\", \"CC\", \"TVB3\", \"tvb\")\n",
        "output = os.path.join(os.path.expanduser(\"~\"), 'Dropbox', 'Work', 'VBtech', 'VEP', \"results\", \"tests\")\n",
        "config = Config(head_folder=tvb_folder, output_base=output, data_mode='tvb')\n",
        "logger = initialize_logger(__name__, config.out.FOLDER_LOGS)\n",
        "tvb_reader = TVBReader() \n",
        "reader = H5Reader()\n",
        "writer = H5Writer()\n",
        "config.figures.SHOW_FLAG = True\n",
        "plotter = Plotter(config)\n",
        "sys.stdout = stdout"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2018-02-22 13:02:33,506 - WARNING - Plotter - Noninteractive matplotlib backend! No highlighting functionality in plots!\n"
          ]
        }
      ],
      "execution_count": 1,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Reading data\n",
        "logger.info(\"Reading from: \" + config.input.HEAD)\n",
        "head = tvb_reader.read_head(config.input.HEAD)\n",
        "# head = reader.read_head(config.input.HEAD)\n",
        "# Plot\n",
        "# plotter.plot_head(head)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2018-02-22 13:02:33,517 - INFO - __main__ - Reading from: /Users/dionperd/Dropbox/Work/VBtech/VEP/results/CC/TVB3/tvb\n"
          ]
        }
      ],
      "execution_count": 2,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "outputExpanded": true,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate an hypothesis..."
      ],
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tvb_epilepsy.service.hypothesis_builder import HypothesisBuilder\n",
        "# Read clinical hypothesis... \n",
        "hyp_builder = HypothesisBuilder(head.connectivity.number_of_regions, config).set_normalize(0.95)"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " ### ...by reading from epileptogenicity file"
      ],
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "e_indices = []\n",
        "hypothesis = hyp_builder.build_hypothesis_from_file(\"clinical_hypothesis_postseeg\", e_indices)        \n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "outputExpanded": true,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ...or by manual definition "
      ],
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#...of formulate a VEP hypothesis manually\n",
        "from tvb_epilepsy.service.hypothesis_builder import HypothesisBuilder\n",
        "\n",
        "hyp_builder = HypothesisBuilder(head.connectivity.number_of_regions, config).set_normalize(0.95)\n",
        "\n",
        "# Regions of Pathological Excitability hypothesis:\n",
        "x0_indices = []\n",
        "x0_values = []\n",
        "\n",
        "# Regions of Model Epileptogenicity hypothesis:\n",
        "e_indices = []\n",
        "e_values = []\n",
        "\n",
        "# Regions of Connectivity hypothesis:\n",
        "w_indices = [(0, 1), (0,2)] # use linear indices for the 2D connectivity matrix\n",
        "w_values = [0.5, 2.0] # wij[w_linear_indice] *= w_value[w_linear_indice]\n",
        "# hypo_builder.set_w_indices(w_indices).set_w_values(w_values)\n",
        "\nhypothesis = hyp_builder.set_x0_hypothesis(x0_indices, x0_values).set_x0_hypothesis(e_indices, e_values).set_w_hypothesis(w_indices, w_values).build_hypothesis()"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "collapsed": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Print hypothesis"
      ],
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "disease_indices = hypothesis.get_regions_disease_indices()\n",
        "disease_values = hypothesis.get_regions_disease_values()\n",
        "w_indices = hypothesis.get_connectivity_disease_indices()\n",
        "w_values = hypothesis.get_connectivity_disease_values()\n",
        "n_w = len(w_indices)\n",
        "n_e = len(e_indices)\n",
        "n_disease = len(disease_indices)\n",
        "n_x0 = n_disease - n_e\n",
        "all_regions_indices = np.array(range(head.number_of_regions))\n",
        "healthy_indices = np.delete(all_regions_indices, disease_indices).tolist()\n",
        "n_healthy = len(healthy_indices)\n",
        "print(hypothesis)\n",
        "for iRegion in range(n_disease):\n",
        "    print disease_indices[iRegion], \". \", head.connectivity.region_labels[disease_indices[iRegion]], disease_values[iRegion]\n",
        "for iConnection in range(n_w):\n",
        "    print w_indices[iConnection][0], \". \", head.connectivity.region_labels[ w_indices[iConnection][0]], \" -> \", \\\n",
        "          w_indices[iConnection][1], \". \", head.connectivity.region_labels[ w_indices[iConnection][1]], \\\n",
        "          w_values[iConnection]\n",
        "print(w_indices)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DiseaseHypothesis{\n",
            "01. Name = w_Hypothesis\n",
            "02. Type = Connectivity\n",
            "03. Number of regions = 87\n",
            "04. X0 disease indices = []\n",
            "05. X0 disease values = []\n",
            "06. e_values disease indices = []\n",
            "07. e_values disease indices = []\n",
            "08. Connectivity disease indices = [[0, 1], [0, 2]]\n",
            "09. Connectivity disease values = [ 0.5  2. ]\n",
            "10. Propagation indices = []\n",
            "11. Propagation strengths of indices = []}\n",
            "0 .  ctx-lh-bankssts  ->  1 .  ctx-lh-caudalanteriorcingulate 0.5\n",
            "0 .  ctx-lh-bankssts  ->  2 .  ctx-lh-caudalmiddlefrontal 2.0\n",
            "[[0, 1], [0, 2]]\n"
          ]
        }
      ],
      "execution_count": 6,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model configuration\n",
        "from tvb_epilepsy.service.model_configuration_service import ModelConfigurationService\n",
        "\n",
        "logger.info(\"\\n\\nCreating model configuration...\")\n",
        "model_configuration_service = ModelConfigurationService(hyp.number_of_regions)\n",
        "model_configuration_service.write_to_h5(FOLDER_RES, hyp.name + \"_model_config_service.h5\")\n",
        "\n",
        "model_configuration = model_configuration_service.configure_model_from_hypothesis(hyp, \n",
        "                                                                                  head.connectivity.normalized_weights)\n",
        "model_configuration.write_to_h5(FOLDER_RES, hyp.name + \"_ModelConfig.h5\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run linear stability analysis\n",
        "from tvb_epilepsy.service.lsa_service import LSAService\n",
        "\n",
        "# Options for eigen_vectors_number: \n",
        "# \"auto_eigenvals\": eigenvalues curve elbow point selection,\n",
        "# \"auto_disease\": len(n_disease), \n",
        "# \"auto_epileptogenicity\": Model Epileptogenicity curve elbow point selection,\n",
        "# \"auto_excitability\": Pathological Excitability curve elbow point selection\n",
        "# or \"user_defined\": a number equal to from 1 to hypothesis.number_of_regions\n",
        "lsa_service = LSAService(eigen_vectors_number=None, \n",
        "                         eigen_vectors_number_selection=\"auto_eigenvals\", \n",
        "                         weighted_eigenvector_sum=True)\n",
        "lsa_hypothesis = lsa_service.run_lsa(hyp, model_configuration)\n",
        "\n",
        "lsa_service.write_to_h5(FOLDER_RES, lsa_hypothesis.name + \"_LSAConfig.h5\")\n",
        "lsa_hypothesis.write_to_h5(FOLDER_RES, lsa_hypothesis.name + \"_LSA.h5\")\n",
        "\n",
        "# Plot\n",
        "lsa_service.plot_lsa(lsa_hypothesis, model_configuration, head.connectivity.region_labels,  None, \n",
        "                     show_flag=SHOW_FLAG, save_flag=SAVE_FLAG, figure_dir=FOLDER_FIGURES, figure_format=FIG_FORMAT)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run parameter search exploration for linear stability analysis around the clinical hypothesis\n",
        "\n",
        "from tvb_epilepsy.base.utils import linear_index_to_coordinate_tuples, dicts_of_lists_to_lists_of_dicts, list_of_dicts_to_dicts_of_ndarrays\n",
        "    \n",
        "pse_params = {\"path\": [], \"indices\": [], \"name\": [], \"samples\": []}\n",
        "\n",
        "# First sample the parameters of interest:\n",
        "from tvb_epilepsy.service.sampling_service import StochasticSamplingService\n",
        "\n",
        "# Some constants\n",
        "n_samples=100\n",
        "half_range = 0.1 \n",
        "MAX_DISEASE_VALUE = 1.0 - 10 ** -3\n",
        "\n",
        "# The connectivity matrix:\n",
        "connectivity_matrix = head.connectivity.normalized_weights\n",
        "\n",
        "# First build from the hypothesis the input parameters of the parameter search exploration.\n",
        "# These can be either originating from excitability, epileptogenicity or connectivity hypotheses,\n",
        "# or they can relate to the global coupling scaling (parameter K of the model configuration)\n",
        "\n",
        "# Pathological Excitability\n",
        "for ii in range(len(lsa_hypothesis.x0_values)):\n",
        "    pse_params[\"indices\"].append([ii])\n",
        "    pse_params[\"path\"].append(\"hypothesis.x0_values\")\n",
        "    pse_params[\"name\"].append(str(head.connectivity.region_labels[lsa_hypothesis.x0_indices[ii]]) + \" Excitability\")\n",
        "\n",
        "    # Now generate samples using a truncated uniform distribution (using inverse sampling with scipy)\n",
        "    sampler = StochasticSamplingService(n_samples=n_samples, n_outputs=1, sampling_module=\"scipy\",\n",
        "                                        random_seed=None,\n",
        "                                        trunc_limits={\"high\": MAX_DISEASE_VALUE},\n",
        "                                        sampler=\"uniform\",\n",
        "                                        loc=lsa_hypothesis.x0_values[ii] - half_range, scale=2 * half_range)\n",
        "    pse_params[\"samples\"].append(sampler.generate_samples())\n",
        "\n",
        "# Model Epileptogenicity\n",
        "for ii in range(len(lsa_hypothesis.e_values)):\n",
        "    pse_params[\"indices\"].append([ii])\n",
        "    pse_params[\"path\"].append(\"hypothesis.e_values\")\n",
        "    pse_params[\"name\"].append(str(head.connectivity.region_labels[lsa_hypothesis.e_indices[ii]]) + \" Epileptogenicity\")\n",
        "\n",
        "    # Now generate samples using a truncated uniform distribution (using inverse sampling with scipy)\n",
        "    sampler = StochasticSamplingService(n_samples=n_samples, n_outputs=1, sampling_module=\"scipy\",\n",
        "                                        random_seed=None,\n",
        "                                        trunc_limits={\"high\": MAX_DISEASE_VALUE},\n",
        "                                        sampler=\"uniform\",\n",
        "                                        loc=lsa_hypothesis.e_values[ii] - half_range, scale=2 * half_range)\n",
        "    pse_params[\"samples\"].append(sampler.generate_samples())\n",
        "\n",
        "# Connectivity\n",
        "for ii in range(len(lsa_hypothesis.w_values)):\n",
        "    pse_params[\"indices\"].append([ii])\n",
        "    pse_params[\"path\"].append(\"hypothesis.w_values\")\n",
        "    inds = linear_index_to_coordinate_tuples(lsa_hypothesis.w_indices[ii], connectivity_matrix.shape)\n",
        "    if len(inds) == 1:\n",
        "        pse_params[\"name\"].append(str(region_labels[inds[0][0]]) + \"-\" +\n",
        "                                    str(region_labels[inds[0][0]]) + \" Connectivity\")\n",
        "    else:\n",
        "        pse_params[\"name\"].append(\"Connectivity[\" + str(inds), + \"]\")\n",
        "\n",
        "    # Now generate samples using a truncated normal distribution (using inverse sampling with scipy)\n",
        "    sampler = StochasticSamplingService(n_samples=n_samples, n_outputs=1, sampling_module=\"scipy\",\n",
        "                                        random_seed=None,\n",
        "                                        trunc_limits={\"high\": MAX_DISEASE_VALUE},\n",
        "                                        sampler=\"norm\", loc=lsa_hypothesis.w_values[ii], scale=half_range)\n",
        "    pse_params[\"samples\"].append(sampler.generate_samples())\n",
        "\n",
        "# Global coupling\n",
        "kloc = model_configuration_service.K_unscaled[0]\n",
        "global_coupling = [{}]\n",
        "for val in global_coupling:\n",
        "    pse_params[\"path\"].append(\"model.configuration.service.K_unscaled\")\n",
        "    inds = val.get(\"indices\", all_regions_indices)\n",
        "    if np.all(inds == all_regions_indices):\n",
        "        pse_params[\"name\"].append(\"Global coupling\")\n",
        "    else:\n",
        "        pse_params[\"name\"].append(\"Afferent coupling[\" + str(inds) + \"]\")\n",
        "    pse_params[\"indices\"].append(inds)\n",
        "\n",
        "    # Now generate samples susing a truncated normal distribution\n",
        "    sampler = StochasticSamplingService(n_samples=n_samples, n_outputs=1, sampling_module=\"scipy\",\n",
        "                                        random_seed=None,\n",
        "                                        trunc_limits={\"low\": 0.0}, sampler=\"norm\", loc=kloc, scale=30 * half_range)\n",
        "    pse_params[\"samples\"].append(sampler.generate_samples())\n",
        "\n",
        "# Convert to a list of dicts\n",
        "pse_params_list = dicts_of_lists_to_lists_of_dicts(pse_params)\n",
        "\n",
        "# Optionally, add a random jitter to the healthy regions Pathological Excitability...:\n",
        "healthy_regions_parameters=[{}]\n",
        "for val in healthy_regions_parameters:\n",
        "    inds = val.get(\"indices\", healthy_indices)\n",
        "    name = val.get(\"name\", \"x0\")\n",
        "    n_params = len(inds)\n",
        "    sampler = StochasticSamplingService(n_samples=n_samples, n_outputs=n_params, sampler=\"uniform\",\n",
        "                                        trunc_limits={\"low\": 0.0}, sampling_module=\"scipy\",\n",
        "                                        random_seed=None,\n",
        "                                        loc=0.0, scale=2 * half_range)\n",
        "\n",
        "    samples = sampler.generate_samples()\n",
        "    for ii in range(n_params):\n",
        "        pse_params_list.append({\"path\": \"model_configuration_service.\" + name, \"samples\": samples[ii],\n",
        "                                    \"indices\": [inds[ii]], \"name\": name})\n",
        "        \n",
        "# Now run pse:\n",
        "from tvb_epilepsy.service.pse_service import PSEService\n",
        "pse = PSEService(\"LSA\", hypothesis=lsa_hypothesis, params_pse=pse_params_list)\n",
        "pse_results, execution_status = pse.run_pse(connectivity_matrix, grid_mode=False, lsa_service_input=lsa_service,\n",
        "                                            model_configuration_service_input=model_configuration_service)\n",
        "\n",
        "# Convert results to a dict of numpy arrays:\n",
        "pse_results = list_of_dicts_to_dicts_of_ndarrays(pse_results)\n",
        "\n",
        "# Plot\n",
        "lsa_service.plot_lsa(lsa_hypothesis, model_configuration, head.connectivity.region_labels, pse_results, \n",
        "                     show_flag=SHOW_FLAG, save_flag=SAVE_FLAG, figure_dir=FOLDER_FIGURES, figure_format=FIG_FORMAT)\n",
        "\n",
        "# Write pse service and results to h5 files\n",
        "pse.write_to_h5(FOLDER_RES, lsa_hypothesis.name + \"_PSE_LSA_Service.h5\")\n",
        "convert_to_h5_model(pse_results).write_to_h5(FOLDER_RES, lsa_hypothesis.name + \"_PSE_LSA_results.h5\")\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Simulation\n",
        "from tvb_epilepsy.base.constants import ADDITIVE_NOISE, NOISE_SEED\n",
        "from tvb_epilepsy.base.utils import calculate_projection\n",
        "from tvb_epilepsy.base.computations.analyzers_utils import filter_data\n",
        "from tvb_epilepsy.base.simulators import SimulationSettings\n",
        "from tvb_epilepsy.base.plot_utils import plot_sim_results\n",
        "from tvb_epilepsy.service.epileptor_model_factory import model_build_dict, model_noise_intensity_dict, model_noise_type_dict\n",
        "from tvb_epilepsy.custom.read_write import write_ts_epi, write_ts_seeg_epi\n",
        "from tvb_epilepsy.custom.simulator_custom import EpileptorModel\n",
        "from tvb_epilepsy.tvb_api.simulator_tvb import SimulatorTVB\n",
        "from tvb_epilepsy.tvb_api.epileptor_models import EpileptorDP2D, EpileptorDPrealistic, EpileptorDP2D\n",
        "\n",
        "from tvb.datatypes import equations\n",
        "from tvb.simulator import monitors, noise\n",
        "from tvb.simulator.models import Epileptor\n",
        "    \n",
        "# Choose the model:\n",
        "# other options: the TVB \"Epileptor\", \n",
        "# the 2D reduced model: \"EpileptorDP2D\", \n",
        "# a model to create realistic simulations: \"EpileptorDPrealistic\" \n",
        "# by coupling Iext2 and slope to the slow z variable + other pink noisy tricks...\n",
        "model_name = \"EpileptorDPrealistic\" \n",
        "# and the variables of interest...\n",
        "VOIS = {\n",
        "    \"JavaEpileptor\": ['x1', 'z', 'x2'],\n",
        "    \"Epileptor\": ['x1', 'y1', 'z', 'x2', 'y2', 'g', 'lfp'],\n",
        "    \"EpileptorDP\": ['x1', 'y1', 'z', 'x2', 'y2', 'g', 'lfp'],\n",
        "    \"EpileptorDPrealistic\": ['x1', 'y1', 'z', 'x2', 'y2', 'g', 'x0ts', 'slopeTS', 'Iext1ts', 'Iext2ts', 'Kts', 'lfp'],\n",
        "    \"EpileptorDP2D\": ['x1', 'z']\n",
        "}\n",
        "\n",
        "# Projections computations: Get gain matrices for every available sensors' set\n",
        "\n",
        "sensorsSEEG = []\n",
        "projections = []\n",
        "for sensors, projection in head.sensorsSEEG.iteritems():\n",
        "    if projection is None:\n",
        "        continue\n",
        "    else:\n",
        "        projection = calculate_projection(sensors, head.connectivity)\n",
        "        head.sensorsSEEG[sensors] = projection\n",
        "        sensorsSEEG.append(sensors)\n",
        "        projections.append(projection)\n",
        "        \n",
        "# Simulation preparations regarding time scales\n",
        "fs = 4096.0 # (in Hz), this is the simulation sampling rate that is necessary for the simulation to be stable\n",
        "time_length = 100000.0  #in msec =100 secs, the final output nominal time length of the simulation\n",
        "scale_time = 2.0 # scaling factor to accelerate  simulation to get the nominal time length in less integration steps\n",
        "# scale_fsavg = 8.0 # scaling factor for the monitor period, it affects the final output sampling time\n",
        "report_every_n_monitor_steps = 100.0\n",
        "dt = 1000.0 / fs #(in msec)\n",
        "scale_fsavg = int(np.round(fs / 512.0))\n",
        "fsAVG = fs / scale_fsavg\n",
        "monitor_period = scale_fsavg * dt / scale_time\n",
        "sim_length = time_length / scale_time\n",
        "time_length_avg = np.round(sim_length / monitor_period)\n",
        "n_report_blocks = max(report_every_n_monitor_steps * np.round(time_length_avg / 100), 1.0)\n",
        "\n",
        "# Filtering options:\n",
        "hpf_flag = False # To high pass filter SEEG or not...\n",
        "hpf_low = max(16.0, 1000.0 / time_length)  # msec\n",
        "hpf_high = min(250.0, fsAVG)\n",
        "\n",
        "# Prepare the model and the simulator:\n",
        "\n",
        "# Create the model\n",
        "model = model_build_dict[model_name](model_configuration, zmode=np.array(\"lin\"))\n",
        "\n",
        "# Set some parameters according to model:\n",
        "if isinstance(model, Epileptor):\n",
        "    model.tt *= scale_time * 0.25\n",
        "    model.r = 0.0001\n",
        "else:\n",
        "    model.tau1 *= scale_time\n",
        "    model.tau0 = 10000.0\n",
        "    if isinstance(model, EpileptorDPrealistic):\n",
        "        model.slope = 0.25\n",
        "        model.pmode = np.array(\"z\")\n",
        "        \n",
        "# Set monitor:\n",
        "monitor_expressions = []\n",
        "for i in range(model._nvar):\n",
        "        monitor_expressions.append(\"y\" + str(i))\n",
        "if not (isinstance(model, EpileptorDP2D)):\n",
        "       monitor_expressions.append(\"y3 - y0\")\n",
        "        \n",
        "model.variables_of_interest = monitor_expressions\n",
        "monitors_instance = monitors.TemporalAverage()\n",
        "monitors_instance.period = monitor_period\n",
        "\n",
        "# Set noise:\n",
        "noise_intensity = model_noise_intensity_dict[model_name]\n",
        "noise_type = model_noise_type_dict[model_name]\n",
        "if noise_type is ADDITIVE_NOISE:\n",
        "    noise_instance = noise.Additive(nsig=noise_intensity, random_stream=np.random.RandomState(seed=NOISE_SEED))\n",
        "    noise_instance.configure_white(dt=dt)\n",
        "\n",
        "else:\n",
        "    eq = equations.Linear(parameters={\"a\": 1.0, \"b\": 0.0})\n",
        "    noise_instance = noise.Multiplicative(ntau=10, nsig=noise_intensity, b=eq,\n",
        "                                          random_stream=np.random.RandomState(seed=NOISE_SEED))\n",
        "    noise_shape = noise_instance.nsig.shape\n",
        "    noise_instance.configure_coloured(dt=dt, shape=noise_shape)\n",
        "    \n",
        "# Create simulator and its settings:\n",
        "settings = SimulationSettings(simulated_period=sim_length, integration_step=dt, scale_time=scale_time,\n",
        "                                  noise_preconfig=noise_instance, noise_type=noise_type,\n",
        "                                  noise_intensity=noise_intensity, noise_ntau=noise_instance.ntau,\n",
        "                                  monitors_preconfig=monitors_instance, monitor_type=monitors_instance._ui_name,\n",
        "                                  monitor_sampling_period=monitor_period, monitor_expressions=monitor_expressions,\n",
        "                                  variables_names=model.variables_of_interest)\n",
        "\n",
        "simulator_instance = SimulatorTVB(head.connectivity, model_configuration, model, settings)\n",
        "\n",
        "# At last configure and run simulation!:\n",
        "simulator_instance.config_simulation()\n",
        "logger.info(\"\\n\\nSimulating...\")\n",
        "ttavg, tavg_data, status = simulator_instance.launch_simulation(n_report_blocks)\n",
        "\n",
        "# Write simulation settings to a h5 file:\n",
        "convert_to_h5_model(simulator_instance.simulation_settings).write_to_h5(FOLDER_RES, lsa_hypothesis.name + \"_Sim_Settings.h5\")\n",
        "\n",
        "if not status:\n",
        "    warnings.warn(\"\\nSimulation failed!\")\n",
        "\n",
        "else:\n",
        "\n",
        "    tavg_data = tavg_data[:, :, :, 0]\n",
        "\n",
        "    vois = VOIS[model_name]\n",
        "\n",
        "    model = simulator_instance.model\n",
        "\n",
        "    logger.info(\"\\n\\nSimulated signal return shape: %s\", tavg_data.shape)\n",
        "    logger.info(\"Time: %s - %s\", scale_time * ttavg[0], scale_time * ttavg[-1])\n",
        "    logger.info(\"Values: %s - %s\", tavg_data.min(), tavg_data.max())\n",
        "\n",
        "    time = scale_time * np.array(ttavg, dtype='float32')\n",
        "    sampling_time = np.min(np.diff(time))\n",
        "\n",
        "    # Pack results into a dictionary:\n",
        "    vois_ts_dict = dict()\n",
        "    for idx_voi, voi in enumerate(vois):\n",
        "        vois_ts_dict[voi] = tavg_data[:, idx_voi, :].astype('f')\n",
        "\n",
        "    # High pass filter, and compute SEEG:\n",
        "    if isinstance(model, EpileptorDP2D):\n",
        "        raw_data = np.dstack([vois_ts_dict[\"x1\"], vois_ts_dict[\"z\"], vois_ts_dict[\"x1\"]])\n",
        "        lfp_data = vois_ts_dict[\"x1\"]\n",
        "\n",
        "        for idx_proj, proj in enumerate(projections):\n",
        "            vois_ts_dict['seeg%d' % idx_proj] = vois_ts_dict['z'].dot(proj.T)\n",
        "\n",
        "    else:\n",
        "        if isinstance(model, EpileptorModel):\n",
        "            lfp_data = vois_ts_dict[\"x2\"] - vois_ts_dict[\"x1\"]\n",
        "\n",
        "        else:\n",
        "            lfp_data = vois_ts_dict[\"lfp\"]\n",
        "\n",
        "        raw_data = np.dstack([vois_ts_dict[\"x1\"], vois_ts_dict[\"z\"], vois_ts_dict[\"x2\"]])\n",
        "\n",
        "        for idx_proj, proj in enumerate(projections):\n",
        "            vois_ts_dict['seeg%d' % idx_proj] = vois_ts_dict['lfp'].dot(proj.T)\n",
        "            if hpf_flag:\n",
        "                for i in range(vois_ts_dict['seeg'].shape[0]):\n",
        "                    vois_ts_dict['seeg_hpf%d' % i][:, i] = filter_data(\n",
        "                        vois_ts_dict['seeg%d' % i][:, i], hpf_low, hpf_high, fsAVG)\n",
        "                    \n",
        "    # Write files:\n",
        "    write_ts_epi(raw_data, dt, lfp_data, FOLDER_RES, lsa_hypothesis.name + \"_ts.h5\")\n",
        "\n",
        "    for i in range(len(projections)):\n",
        "        write_ts_seeg_epi(vois_ts_dict['seeg%d' % i], dt, FOLDER_RES, lsa_hypothesis.name + \"_ts.h5\")\n",
        "\n",
        "    vois_ts_dict['time'] = time\n",
        "    vois_ts_dict['time_units'] = 'msec'\n",
        "    \n",
        "    # Optionally write a MATLAB file as well\n",
        "    from scipy.io import savemat\n",
        "    savemat(os.path.join(FOLDER_RES, lsa_hypothesis.name + \"_ts.mat\"), vois_ts_dict)\n",
        "\n",
        "    # Plot results\n",
        "    plot_sim_results(model, lsa_hypothesis.propagation_indices, lsa_hypothesis.name, head, vois_ts_dict, sensorsSEEG, hpf_flag, \n",
        "                     save_flag=SAVE_FLAG, show_flag=SHOW_FLAG, figure_dir=FOLDER_FIGURES, figure_format=FIG_FORMAT)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "scrolled": true
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true
      }
    }
  ],
  "metadata": {
    "hide_input": false,
    "kernelspec": {
      "name": "python2",
      "language": "python",
      "display_name": "Python 2"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.12",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 2,
        "name": "ipython"
      }
    },
    "latex_envs": {
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 0
    },
    "nav_menu": {},
    "toc": {
      "navigate_menu": true,
      "number_sections": true,
      "sideBar": true,
      "threshold": 6,
      "toc_cell": false,
      "toc_section_display": "block",
      "toc_window_display": false
    },
    "kernel_info": {
      "name": "python2"
    },
    "nteract": {
      "version": "0.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}